{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondaf0cc2438f81e4bd89084fc3f46344499",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_contrib'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-854aea30d233>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mReshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_contrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstancenormalization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInstanceNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvanced_activations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_contrib'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.layers import Input,Dense,Reshape,Flatten,Dropout,BatchNormalization,Lambda,concatenate\n",
    "from keras.layers.core import Activation\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam,SGD,nadam,Adamax\n",
    "import keras.backend as k\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-4-c3d9d66e3eb6>, line 2)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-c3d9d66e3eb6>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(object):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gan import GAN\n",
    "# from generator import Generator\n",
    "# from discriminator import Discriminator\n",
    "from keras.layers import Input\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "duplicate argument 'test_data_path_A' in function definition (<ipython-input-9-01075ad87791>, line 5)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-01075ad87791>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    self.EPOCHS =  epochs\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m duplicate argument 'test_data_path_A' in function definition\n"
     ]
    }
   ],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,height=64,width=64,epochs=50000,batch=32,checkpoint=50,\n",
    "                 train_data_path_A='',train_data_path_B='',\n",
    "                 test_data_path_A='',test_data_path_A=''):\n",
    "        self.EPOCHS =  epochs\n",
    "        self.BATCH = batch\n",
    "        self.RESIZE_HEIGHT = height\n",
    "        self.RESIZE_WIDTH = width\n",
    "        self.CHECKPOINT = checkpoint\n",
    "\n",
    "        # train셋과 test셋 A,B 두개(총 4개)\n",
    "        self.X_train_A,self.H_A,self.W_A,self.C_A = self.load_data(train_data_path_A)\n",
    "        self.X_train_B,self.H_B,self.W_B,self.C_B = self.load_data(train_data_path_B)\n",
    "\n",
    "        self.X_train_A,self.H_A,self.W_A,self.C_A = self.load_data(train_data_path_A)\n",
    "        self.X_train_B,self.H_B,self.W_B,self.C_B = self.load_data(train_data_path_B)\n",
    "\n",
    "        # generator A2B,B2A로 2개\n",
    "        self.generator_A_to_B = Generator(height=self.H_A,width=self.W_A,channels=self.C_A)\n",
    "        self.generator_B_to_A = Generator(height=self.H_B,width=self.W_B,channels=self.C_B)\n",
    "\n",
    "\n",
    "        # 내용 추가\n",
    "        self.orig_A = Input(shape=(self.W_A,self.H_A,self.C_A))\n",
    "        self.orig_B = Input(shape=(self.W_B,self.H_B,self.C_B))\n",
    "\n",
    "        # fake_A, fake_B(원래 -> 가짜)\n",
    "        self.fake_B = self.generator_A_to_B.Generator(self.orig_A)\n",
    "        self.fake_A = self.generator_B_to_A.Generator(self.orig_B)\n",
    "\n",
    "        # reconstruced(가짜 -> 원래)\n",
    "        self.reconstructed_A = self.generator_B_to_A.Generator(self.fake_B)\n",
    "        self.reconstructed_B = self.generator_A_to_B.Generator(self.fake_A)\n",
    "\n",
    "        self.id_A = self.generator_B_to_A.Generator(self.orig_A)\n",
    "        self.id_B = self.generator_A_to_B.Generator(self.orig_B)\n",
    "\n",
    "        # 판별기\n",
    "        self.discriminator_A = Discriminator(height=self.H_A,width=self.W_A,channels=self.C_A)\n",
    "        self.discriminator_B = Discriminator(height=self.H_B,width=self.W_B,channels=self.C_B)\n",
    "        # 판별기 훈련 x\n",
    "        self.discriminator_A.trainable = False\n",
    "        self.discriminator_B.trainable = False\n",
    "        self.valid_A = self.discriminator_A.Discriminator(self.fake_A)\n",
    "        self.valid_B = self.discriminator_B.Discriminator(self.fake_B)\n",
    "\n",
    "        model_inputs = [self.orig_A,self.orig_B]\n",
    "        model_outputs = [self.valid_A,self.valid_B,\n",
    "                         self.reconstructed_A,self.reconstructed_B,\n",
    "                         self.id_A,self.id_B]\n",
    "        self.gan = GAN(model_inputs=model_inputs,\n",
    "                       model_outputs=model_outputs,\n",
    "                       lambda_cycle=10.0,\n",
    "                       lambda_id=1.0)\n",
    "        \n",
    "        def train(self):\n",
    "            for e in range(self.EPOCHS):\n",
    "                b = 0\n",
    "                X_train_A_temp = deepcopy(self.X_train_A)\n",
    "                X_train_B_temp = deepcopy(self.X_train_B)\n",
    "                while min(len(X_train_A_temp),len(X_train_B_temp)) > self.BATCH:\n",
    "                    b = b + 1\n",
    "                    # A,B에서 진짜 이미지 선택\n",
    "                    count_real_images = int(self.BATCH)\n",
    "                    starting_indexs = randint(0,(min(len(X_train_A_temp),len(X_train_B_temp)) - count_real_images))\n",
    "                    real_images_raw_A = X_train_A_temp[starting_indexs:(starting_indexs + count_real_images)]\n",
    "                    real_images_raw_B = X_train_B_temp[starting_indexs:(starting_indexs + count_real_images)]\n",
    "\n",
    "                    # 선택된 이미지들 지워줌\n",
    "                    X_train_A_temp = np.delete(X_train_A_temp.range(starting_indexs,(starting_indexs + count_real_images)),0)\n",
    "                    X_train_B_temp = np.delete(X_train_B_temp.range(starting_indexs,(starting_indexs + count_real_images)),0)\n",
    "\n",
    "                    batch_A = real_images_raw_A.reshape(count_real_images,self.W_A,self.H_A,self.C_A)                    \n",
    "                    batch_A = real_images_raw_A.reshape(count_real_images,self.W_A,self.H_A,self.C_A)\n",
    "\n",
    "                    if self.flipCoin():\n",
    "                        x_batch_A = batch_A\n",
    "                        x_batch_B = batch_B\n",
    "                        y_batch_A = np.ones([count_real_images,1])\n",
    "                        y_batch_B = np.ones([count_real_images,1])\n",
    "                    else:\n",
    "                        x_batch_A = self.generator_B_to_A.Generator.predict(batch_B)\n",
    "                        x_batch_B = self.generator_A_to_B.Generator.predict(batch_A)\n",
    "                        y_batch_A = np.zeros([self.BATCH,1])\n",
    "                        y_batch_B = np.zeros([self.BATCH,1])\n",
    "                    \n",
    "                    # 판별기 A와 판별기 B를 작성한다.\n",
    "                    self.discriminator_A.Discriminator.trainable = True\n",
    "                    discriminator_loss_A = self.discriminator_A.Discriminator.train_on_batch(x_batch_A,y_batch_A)[0]\n",
    "                    self.discriminator_A.Discriminator.trainable = False\n",
    "\n",
    "                    self.discriminator_B.Discriminator.trainable = True\n",
    "                    discriminator_loss_B = self.discriminator_B.Discriminator.train_on_batch(x_batch_B,y_batch_B)[0]\n",
    "                    self.discriminator_B.Discriminator.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "                    # 점검\n",
    "                    print (f'Batch: {str(int(b))}, [Full Discriminator :: Loss: {str(full_loss)}], [ Generator :: Loss: {str(generator_loss)}]')\n",
    "                    if b % self.CHECKPOINT == 0 :\n",
    "                        label = str(e)+'_'+str(b)\n",
    "                        self.plot_checkpoint(label)\n",
    "\n",
    "                print (f'Epoch: {str(int(e))}, [Full Discriminator :: Loss: {str(full_loss)}], [ Generator :: Loss: {str(generator_loss)}]'')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # 기타 함수\n",
    "        def load_data(self,data_path,amount_of_data = 1.0):\n",
    "            listOFFiles = self.grabListOfFiles(data_path,extension=\"jpg\")\n",
    "            X_train = np.array(self.grabArrayOfImages(listOFFiles))\n",
    "            height, width, channels = np.shape(X_train[0])\n",
    "            X_train = X_train[:int(amount_of_data*float(len(X_train)))]\n",
    "            X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "            X_train = np.expand_dims(X_train, axis=3)\n",
    "            return X_train, height, width, channels\n",
    "\n",
    "        # 파일 목록 찾기\n",
    "        def grabListOfFiles(self,startingDirectory,extension='.webp'):\n",
    "            listOfFiles = []\n",
    "            for file in os.listdir(startingDirectory):\n",
    "                if file.endswith(extension):\n",
    "                    listOfFiles.append(os.path.join(startingDirectory,file))\n",
    "            return listOfFiles\n",
    "\n",
    "        # 동전 던지기\n",
    "        def flipCoin(self,chance=0.5):\n",
    "            return np.random.binomial(1,chance)\n",
    "\n",
    "        \n",
    "        # 이미지 가져오기\n",
    "        def grabArrayOfImages(self,listOfFiles,gray=False):\n",
    "            imageArr = []\n",
    "            for f in listOfFiles:\n",
    "                if gray:\n",
    "                    im = Image.open(f).convert(\"L\")\n",
    "                else:\n",
    "                    im = Image.open(f).convert(\"RGB\")\n",
    "                imData = np.asarray(im)\n",
    "                imageArr.append(imData)\n",
    "            return imageArr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  }
 ]
}